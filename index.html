<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI-Based Drowsiness Detection System with Multiparameter Driver Monitoring and IR Night Vision Support</title>
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background: #f4f7fb;
      color: #333;
      line-height: 1.6;
    }
    header {
      background: #2c3e50;
      color: #fff;
      padding: 2rem 1rem;
      text-align: center;
    }
    header h1 { margin: 0; font-size: 2.5rem; }
    header p { font-size: 1.2rem; }
    nav {
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      background: #34495e;
    }
    nav a {
      color: #fff;
      padding: 0.8rem 1.2rem;
      text-decoration: none;
      font-weight: bold;
    }
    nav a:hover { background: #1abc9c; }
    section { padding: 2rem 5%; }
    h2 {
      color: #2c3e50;
      border-left: 5px solid #1abc9c;
      padding-left: 10px;
    }
    .card {
      background: #fff;
      padding: 1.5rem;
      margin: 1rem 0;
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
    }
    ul, ol { margin: 0; padding-left: 20px; }
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 1rem 0;
    }
    table, th, td {
      border: 1px solid #999;
      padding: 10px;
      text-align: left;
    }
    th { background: #1abc9c; color: white; }
    footer {
      background: #2c3e50;
      color: #fff;
      text-align: center;
      padding: 1rem;
      margin-top: 2rem;
    }
    .portfolio-links a {
      display: inline-block;
      margin: 0.5rem;
      padding: 0.7rem 1.2rem;
      border-radius: 6px;
      background: #1abc9c;
      color: white;
      text-decoration: none;
    }
    .portfolio-links a:hover { background: #16a085; }
  </style>
</head>
<body>
  <header>
    <h1>AI-Based Drowsiness Detection System</h1>
    <p>Multiparameter Driver Monitoring & IR Night Vision Support</p>
  </header>

  <nav>
    <a href="#intro">Introduction</a>
    <a href="#aim">Aim</a>
    <a href="#objectives">Objectives</a>
    <a href="#literature">Literature</a>
    <a href="#methodology">Methodology</a>
    <a href="#diagram">Block Diagram</a>
    <a href="#components">Components</a>
    <a href="#software">Software</a>
    <a href="#timeline">Timeline</a>
    <a href="#outcomes">Outcomes</a>
    <a href="#references">References</a>
    <a href="#portfolio">Portfolio</a>
  </nav>

  <!-- INTRO -->
  <section id="intro">
    <h2>Introduction</h2>
    <div class="card">
      <p>Road accidents are a leading cause of death worldwide, with driver drowsiness contributing to nearly 20–40% of cases. Existing solutions mostly focus only on visual detection, which can be unreliable in low-light conditions and may lead to false alarms.Physiological changes such as drop in heart rate, variations in SpO₂, and irregular body temperature occur during fatigue or drowsiness, and may also signal early cardiac abnormalities. Hence, combining AI-based visual monitoring with physiological tracking provides a more reliable and medically relevant approach. By integrating IR-supported night vision, multiparameter health monitoring, crash detection, and mobile app alerts, the proposed system offers a comprehensive driver safety solution that addresses both behavioral and physiological risks.
</p>
    </div>
  </section>

  <!-- AIM -->
  <section id="aim">
    <h2>Aim</h2>
    <div class="card">
      <p>TTo develop an AI-based drowsiness detection system enhanced with multiparameter driver monitoring and IR night vision support for improved road safety.
</p>
    </div>
  </section>

  <!-- OBJECTIVES -->
  <section id="objectives">
    <h2>Objectives</h2>
    <div class="card">
      <ul>
        <li>Detect driver drowsiness using AI-based vision with IR support.</li>
        <li>Monitor heart rate, SpO₂, body temperature.</li>
        <li>Detect crash events using accelerometer (ADXL345).</li>
        <li>Provide alerts via buzzer + mobile application.</li>
      </ul>
    </div>
  </section>

<!-- LITERATURE -->
<section id="literature">
  <h2>Literature Survey</h2>
  <div class="card" style="text-align:center;">
    <img src="lr1.png" alt="Literature Survey Page 1" style="max-width:90%; margin-bottom:20px; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.2);">
    <img src="lr2.png" alt="Literature Survey Page 2" style="max-width:90%; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.2);">
  </div>
</section>


  <!-- METHODOLOGY -->
<section id="methodology">
  <h2>Methodology</h2>
  <div class="card">
    <h3>1. Data Acquisition</h3>
    <ul>
      <li>IR-enabled camera continuously monitors the driver’s face, effective in both daylight and low-light/night conditions.</li>
      <li>Physiological parameters:</li>
      <ul>
        <li>MAX30102 → Heart Rate (HR), SpO₂</li>
        <li>MLX90614 → Body temperature</li>
        <li>MQ-3 → Alcohol detection</li>
        <li>ADXL345 → Crash detection</li>
        <li>Wearable single-lead ECG module → Continuous HR & HRV monitoring</li>
      </ul>
    </ul>

    <h3>2. AI-based Visual Processing</h3>
    <ul>
      <li>Computer vision algorithms (OpenCV / CNN) analyze facial features.</li>
      <li>Drowsiness detection through eye closure (PERCLOS), yawning frequency, and head posture analysis.</li>
      <li>IR support ensures night-time reliability.</li>
    </ul>

    <h3>3. Physiological Signal Processing</h3>
    <ul>
      <li>ECG-derived HRV, SpO₂, HR, and body temperature are processed as supportive evidence of drowsiness.</li>
      <li>ECG also enables early alerts for cardiac irregularities.</li>
    </ul>

    <h3>4. Multimodal Fusion</h3>
    <ul>
      <li>Visual + physiological features are integrated.</li>
      <li>Final decision made using rule-based thresholds or lightweight ML model to minimize false positives and improve robustness.</li>
    </ul>

    <h3>5. Alert and Communication System</h3>
    <ul>
      <li>Local alerts: buzzer for immediate driver feedback.</li>
      <li>Mobile Application (Firebase cloud): displays vitals, drowsiness state, and sends real-time notifications.</li>
    </ul>

    <h3>6. Crash Detection</h3>
    <ul>
      <li>ADXL345 accelerometer identifies abnormal impacts.</li>
      <li>Crash events trigger emergency alerts through the mobile app.</li>
    </ul>
  </div>
</section>

<!-- BLOCK DIAGRAM -->
<section id="diagram">
  <h2>Block Diagram (Preliminary)</h2>
  <div class="card" style="text-align:center;">
    <img src="lr3.png" alt="Preliminary Block Diagram" style="max-width:95%; border-radius:8px; box-shadow:0 4px 8px rgba(0,0,0,0.2);">
  </div>
</section>

  <!-- COMPONENTS -->
<section id="components">
  <h2>Components</h2>
  <div class="card">
    <ul>
      <li>IR Enabled Camera</li>
      <li>ADXL345 (Accelerometer)</li>
      <li>Buzzer</li>
      <li>Power Supply</li>
      <li>Breadboard</li>
      <li>Rechargeable Battery Pack</li>
      <li>Single-lead ECG module</li>
      <li>MAX30102 (Heart Rate & SpO₂ sensor)</li>
      <li>MLX90614 (Temperature sensor)</li>
      <li>ESP8266 Microcontroller</li>
    </ul>
  </div>
</section>

<!-- SOFTWARE -->
<section id="software">
  <h2>Software</h2>
  <div class="card">
    <ul>
      <li>Arduino IDE</li>
      <li>Microcontroller USB driver</li>
      <li>ECG Sensor Library</li>
      <li>MAX30102 Sensor Library</li>
      <li>Python with NumPy, SciPy, Matplotlib (filtering & plotting)</li>
      <li>MATLAB (Signal analysis)</li>
      <li>OpenCV (video capture & processing)</li>
      <li>Face & eye detection libraries (Dlib – not confirmed)</li>
      <li>Firebase (cloud-based monitoring)</li>
    </ul>
  </div>
</section>

<!-- TIMELINE -->
<section id="timeline">
  <h2>Timeline</h2>
  <div class="card">
    <table>
      <tr><th>Week</th><th>Task</th></tr>
      <tr><td>1</td><td>Procurement of components and hardware setup</td></tr>
      <tr><td>2</td><td>Microcontroller programming for ECG and SpO₂ data acquisition</td></tr>
      <tr><td>3</td><td>Integration of IR camera module for eye closure and blink detection</td></tr>
      <tr><td>4</td><td>Implementation of head nodding and yawning detection algorithms in the microcontroller</td></tr>
      <tr><td>5</td><td>Decision logic integration: alerts for abnormal ECG, SpO₂, and fatigue</td></tr>
      <tr><td>6</td><td>IoT module setup: mobile app/cloud integration for real-time data monitoring</td></tr>
      <tr><td>7</td><td>Prototype testing on volunteers / simulated environment; data logging and debugging</td></tr>
      <tr><td>8</td><td>Refinement of hardware, software, and alert system based on test results</td></tr>
      <tr><td>9</td><td>Final prototype demonstration and preparation of report & presentation</td></tr>
    </table>
  </div>
</section>

  <!-- OUTCOMES -->
<section id="outcomes">
  <h2>Expected Outcomes</h2>
  <div class="card">
    <ul>
      <li>The prototype can detect driver fatigue and drowsiness using IR camera analysis of eye closure, blinking, head nodding, and yawning.</li>
      <li>It also monitors the driver’s heart rate (ECG) and blood oxygen (SpO₂) in real time.</li>
      <li>The system alerts the driver immediately with visual and audio warnings when abnormal vitals or fatigue are detected.</li>
      <li>It sends real-time data to a mobile app or cloud platform for remote monitoring.</li>
      <li>Overall, the prototype helps prevent accidents by alerting drivers before fatigue or health issues become critical.</li>
    </ul>
  </div>
</section>

<!-- REFERENCES -->
<section id="references">
  <h2>References</h2>
  <div class="card">
    <ol>
      <li>Y. Albadawi, M. Takruri, and M. Awad, “A Review of Recent Developments in Driver Drowsiness Detection Systems,” <i>Sensors</i>, vol. 22, no. 5, p. 2069, Mar. 2022. <a href="https://doi.org/10.3390/s22052069" target="_blank">DOI</a></li>
      <li>R. C.-H. Chang, C.-Y. Wang, W.-T. Chen, and C.-D. Chiu, “Drowsiness Detection System Based on PERCLOS and Facial Physiological Signal,” <i>Sensors</i>, vol. 22, no. 14, p. 5380, Jan. 2022. <a href="https://doi.org/10.3390/s22145380" target="_blank">DOI</a></li>
      <li>H.-Y. Lin and K.-C. Tu, “A Technique for Authentic Fatigue Driving Detection Using Nighttime Infrared Images,” <i>Communications in Computer and Information Science</i>, pp. 123–145, Sep. 2024. <a href="https://doi.org/10.1007/978-3-031-70966-1_6" target="_blank">DOI</a></li>
      <li>L. Lalka, P. Mogana Priya, S. Patil, and K. Napte, “Camera-Based Driver Drowsiness Detector,” IRJET, 2021. <a href="https://www.irjet.net/archives/V8/i7/IRJET-V8I7116.pdf" target="_blank">Link</a></li>
      <li>C. Kumar and B. Bhowmick, “An Application for Driver Drowsiness Identification based on Pupil Detection using IR Camera,” Springer eBooks, pp. 73–82, Jan. 2009. <a href="https://doi.org/10.1007/978-81-8489-203-1_5" target="_blank">DOI</a></li>
      <li>T. S. Delwar et al., “AI- and Deep Learning-Powered Driver Drowsiness Detection Method Using Facial Analysis,” <i>Applied Sciences</i>, vol. 15, no. 3, p. 1102, Jan. 2025. <a href="https://doi.org/10.3390/app15031102" target="_blank">DOI</a></li>
      <li>A. A. Saleem et al., “A systematic review of physiological signals based driver drowsiness detection systems,” <i>Cognitive Neurodynamics</i>, Oct. 2022. <a href="https://doi.org/10.1007/s11571-022-09898-9" target="_blank">DOI</a></li>
      <li>M. Doudou, A. Bouabdallah, and V. Berge-Cherfaoui, “Driver Drowsiness Measurement Technologies: Current Research, Market Solutions, and Challenges,” <i>International Journal of Intelligent Transportation Systems Research</i>, vol. 18, no. 2, pp. 297–319, Sep. 2019. <a href="https://doi.org/10.1007/s13177-019-00199-w" target="_blank">DOI</a></li>
      <li>S. Kumar, P. Devi, M. Singh, and M. Rani, “Driver Drowsiness Detection System,” <i>International Journal of Science and Research Archive</i>, vol. 12, no. 1, pp. 1017–1022, May 2024. <a href="https://doi.org/10.30574/ijsra.2024.12.1.0935" target="_blank">DOI</a></li>
      <li>K.-J. Kim, K.-T. Lim, J. W. Baek, and M. Shin, “Low-Cost Real-time Driver Drowsiness Detection based on Convergence of IR Images and EEG Signals,” Apr. 2021. <a href="https://doi.org/10.1109/icaiic51459.2021.9415193" target="_blank">DOI</a></li>
    </ol>
  </div>
</section>

